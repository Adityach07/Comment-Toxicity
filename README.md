# Comment Toxicity Classification

## Overview
This project focuses on developing a model to classify comments for toxicity, enhancing online content moderation and ensuring safer user interactions. The model utilizes deep learning techniques, specifically a Bidirectional Long Short-Term Memory (BiLSTM) architecture, to analyze and classify text data.

## Table of Contents
- [Technologies Used](#technologies-used)
- [Dataset](#dataset)
- [Installation](#installation)
- [Usage](#usage)
- [Model Evaluation](#model-evaluation)
- [Contributing](#contributing)
- [License](#license)

## Technologies Used
- Python
- TensorFlow/Keras
- Scikit-learn
- Pandas
- NumPy
- Matplotlib
- Jupyter Notebook

## Dataset
The dataset used for this project consists of annotated comments, where each comment is labeled as toxic or non-toxic. [Include a link to the dataset or describe how to obtain it.]

## Installation
To run this project locally, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/Adityach07/comment-toxicity-classification.git
   cd comment-toxicity-classification
